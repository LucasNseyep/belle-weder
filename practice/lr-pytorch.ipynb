{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa9e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Library\n",
    "import torch\n",
    "# PyTorch Neural Network\n",
    "import torch.nn as nn\n",
    "# Allows us to transform data\n",
    "import torchvision.transforms as transforms\n",
    "# Allows us to get the digit dataset\n",
    "import torchvision.datasets as dsets\n",
    "# Creating graphs\n",
    "import matplotlib.pylab as plt\n",
    "# Allows us to use arrays to manipulate and store data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd06579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to plot parameters\n",
    "\n",
    "def PlotParameters(model):\n",
    "    W = model.state_dict()['linear.weight'].data\n",
    "    w_min = W.min().item()\n",
    "    w_max = W.max().item()\n",
    "    fig, axes = plt.subplots(2, 5)\n",
    "    fig.subplots_adjust(hspace=0.01, wspace=0.1)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < 10:\n",
    "\n",
    "            # Set the label for the sub-plot.\n",
    "            ax.set_xlabel(\"class: {0}\".format(i))\n",
    "\n",
    "            # Plot the image.\n",
    "            ax.imshow(W[i, :].view(28, 28), vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        # Ensure the plot is shown correctly with multiple plots\n",
    "        # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c57ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a26564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and print the training dataset\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the training dataset:\\n \", train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43388083",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = dsets.MNIST(root='./data', download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the validation dataset:\\n \", validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11759bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first image and label\n",
    "\n",
    "print(\"First Image and Label\")\n",
    "show_data(train_dataset[0])\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcaf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the label\n",
    "\n",
    "print(\"The label: \", train_dataset[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image\n",
    "\n",
    "print(\"The image: \")\n",
    "show_data(train_dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image\n",
    "\n",
    "show_data(train_dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177dcb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax Classification\n",
    "\n",
    "class SoftMax(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SoftMax, self).__init__()\n",
    "        # Creates a layer of given input size and output size\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        # Runs the x value through the single layers defined above\n",
    "        z = self.linear(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd72a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input size and output size\n",
    "\n",
    "input_dim = 28 * 28\n",
    "\n",
    "# Our output i sthe probability of each digit classification\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "# Input dim is 28*28 which is the image converted to a tensor\n",
    "# Output dim is 10 because there are 10 possible digits the image can be\n",
    "model = SoftMax(input_dim, output_dim)\n",
    "print(\"Print the model:\\n \", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the parameters\n",
    "\n",
    "print('W: ',list(model.parameters())[0].size())\n",
    "print('b: ',list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model parameters for each class\n",
    "# Since the model has not been trained yet the parameters look random\n",
    "\n",
    "PlotParameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec25d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get the X value of the first image\n",
    "X = train_dataset[0][0]\n",
    "# We can see the shape is 1 by 28 by 28, we need it to be flattened to 1 by 28 * 28 (784)\n",
    "print(X.shape)\n",
    "X = X.view(-1, 28*28)\n",
    "print(X.shape)\n",
    "# Now we can make a prediction, each class has a value, and the higher it is the more confident the model is that it is that digit\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a31162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate, optimizer, criterion, and data loader\n",
    "\n",
    "learning_rate = 0.1\n",
    "# The optimizer will update the model parameters using the learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# The criterion will measure the loss between the prediction and actual label values\n",
    "# This is where the SoftMax occurs, it is built into the Criterion Cross Entropy Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Created a training data loader so we can set the batch size\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n",
    "# Created a validation data loader so we can set the batch size\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
